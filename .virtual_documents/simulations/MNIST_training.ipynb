


import numpy as np
import sys,os
sys.path.append(os.getcwd()[:-11]+'src/')
from models import *
from topological_methods import *
import matplotlib.pyplot as plt
clrs = plt.cm.tab20.colors


from torchvision import datasets, transforms

transform=transforms.Compose([transforms.ToTensor()])

data_train = datasets.MNIST('/Users/kosio/Data/MNIST/', train=True, transform=transform, download=True)
data_test = datasets.MNIST('/Users/kosio/Data/MNIST/', train=False, transform=transform,download=True)

trainloader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True)
testloader = torch.utils.data.DataLoader(data_test, batch_size=64, shuffle=True)



#output before training
model = FeedforwardNetwork(input_size=data_train.data.shape[1]*data_train.data.shape[2]
                           ,hidden_sizes=[1000,500,250,100], out_layer_sz=10, init_type='normal',
                          mean = 0, std=0.01)
model_pos = FeedforwardNetwork(input_size=data_train.data.shape[1]*data_train.data.shape[2]
                           ,hidden_sizes=[1000,500,250,100], out_layer_sz=10, init_type='normal',
                          mean = 0.0001, std=0.0001)
#                          mean = 0, std=1)
net_rank_ratio = 0.1
for layer in model_pos.layers[:-1]:
    if isinstance(layer, nn.Linear):
        R = torch.eye(layer.weight.shape[0])
        rand_inds = np.random.choice(np.arange(0,layer.weight.shape[0]),
                                     size=int(net_rank_ratio*layer.weight.shape[0]), replace=False)
        R[rand_inds,rand_inds] = -1
        layer.weight = torch.nn.Parameter(R@layer.weight)#torch.nn.Parameter(layer.weight+0.0001)#

out = model(data_test.data.reshape(len(data_test.data),-1).float())
out_code = [torch.sum(out[i]>0,axis=1) for i in range(len(out))]

out_pos = model_pos(data_test.data.reshape(len(data_test.data),-1).float())
out_code_pos = [torch.sum(out_pos[i]>0,axis=1) for i in range(len(out))]



#show the PCA spectrum of the MNIST data
from sklearn.decomposition import PCA
reduced_MNIST = PCA().fit(data_test.data.reshape(len(data_test.data),-1).float())
reduced_output = PCA().fit(out[-1].detach().numpy())
reduced_output_pos = PCA().fit(out_pos[-2].detach().numpy())

plt.plot(np.arange(1,785),reduced_MNIST.explained_variance_ratio_,'k-o')
plt.plot(np.arange(1,len(reduced_output.explained_variance_ratio_)+1),reduced_output.explained_variance_ratio_,'r-o')
plt.plot(np.arange(1,len(reduced_output_pos.explained_variance_ratio_)+1),reduced_output_pos.explained_variance_ratio_,'g-o')
plt.xscale('log')


#Train
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
optimizer_pos = optim.Adam(model_pos.parameters(), lr=0.001)

# Define the training function
def train_model(model, trainloader, criterion, optimizer, num_epochs=20):
    model.train()  # Set the model to training mode
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            optimizer.zero_grad()

            outputs = model(inputs.reshape(len(inputs),-1))[-1]
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            if i % 500 == 99:
                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 500))
                running_loss = 0.0

    print('Finished Training')

# Train the model
train_model(model, trainloader, criterion, optimizer)
train_model(model_pos, trainloader, criterion, optimizer_pos)


#output after training
out_post = model(data_test.data.reshape(len(data_test.data),-1).float())
out_code_post = [torch.sum(out_post[i]>0,axis=1) for i in range(len(out_post))]

out_post_pos = model_pos(data_test.data.reshape(len(data_test.data),-1).float())
out_code_post_pos = [torch.sum(out_post_pos[i]>0,axis=1) for i in range(len(out_post_pos))]


[plt.hist(out_code[i],np.linspace(torch.min(out_code[i]),torch.max(out_code[i]),
                                  torch.max(out_code[i])-torch.min(out_code[i])),
                                  color='red',alpha = i*0.3+0.2,density=True) for i in range(len(out_code)-1)]
_ = [plt.hist(out_code_post[i],np.linspace(torch.min(out_code_post[i]),torch.max(out_code_post[i]),
                                  torch.max(out_code_post[i])-torch.min(out_code_post[i])),
                                  color='blue',alpha = i*0.3+0.2,density=True) for i in range(len(out_code_post)-1)]



#[plt.hist(out_code_pos[i],1,color='purple',alpha = i*0.1+0.4,density=True) for i in range(len(out_code_pos)-1)]
_ = [plt.hist(out_code_post_pos[i],np.linspace(torch.min(out_code_post_pos[i]),torch.max(out_code_post_pos[i]),
                                      torch.max(out_code_post_pos[i])-torch.min(out_code_post_pos[i])),
                                      color='green',alpha = i*0.3+0.2,density=True) for i in range(len(out_code_post_pos)-1)]




