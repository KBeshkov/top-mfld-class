{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c405f36a-d310-4a06-92ec-e37d50a2566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "sys.path.append(os.getcwd()[:-11]+'src/')\n",
    "from models import *\n",
    "from topological_methods import *\n",
    "import matplotlib.pyplot as plt\n",
    "clrs = plt.cm.tab20.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc202665-5780-4432-8cb4-ae6df4ce89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "out_dims = [2,5,10,25,50,100]#,500,1000]\n",
    "in_dims = [2,5,10,25,50,100]\n",
    "\n",
    "def code_equivalence_class(code,ranks,min_rank=2): #function to compute equivalence classes\n",
    "    uniq_els = np.unique(code, return_inverse=True,axis=0)\n",
    "    code_list = [[] for i in range(len(uniq_els[0]))]\n",
    "    uniq_code = uniq_els[1]\n",
    "    uniq_code[ranks<min_rank] = 0\n",
    "    #uniq_code = uniq_code/np.max(uniq_code)\n",
    "    for i, uind in enumerate(uniq_els[1]):\n",
    "        if ranks[i]<min_rank:\n",
    "            code_list[uind].append(i)\n",
    "    code_list = [code_list[i] for i in range(len(code_list)) if len(code_list[i])>1]\n",
    "    return code_list, uniq_code\n",
    "\n",
    "res = 1024\n",
    "\n",
    "Phom = PersistentHomology()\n",
    "reducer = MDS(n_components=3, normalized_stress='auto',dissimilarity='precomputed')\n",
    "#Isomap(n_components=3,n_neighbors=4,metric='precomputed')\n",
    "metric = pairwise_distances#GeodesicKNN(k=8,adaptive=True).fit\n",
    "Mfld = ManifoldGenerator()\n",
    "S1 = torch.Tensor(Mfld.S1(res,1))\n",
    "T2 = torch.Tensor(Mfld.T2(int(np.sqrt(res)),1,0.5))#Mfld.T2F(int(np.sqrt(res)),1))#\n",
    "\n",
    "codes_S1 = np.zeros([len(in_dims),len(out_dims),res])\n",
    "codes_T2 = np.zeros([len(in_dims),len(out_dims),res])\n",
    "\n",
    "out_dims = [2,3,5,200]\n",
    "in_dims = [2,3,5,200]\n",
    "n_perms = 1\n",
    "\n",
    "region_ranks_S1 = np.zeros([len(in_dims),len(out_dims),n_perms,res])\n",
    "region_ranks_T2 = np.zeros([len(in_dims),len(out_dims),n_perms,res])\n",
    "\n",
    "S1_dmats = []\n",
    "T2_dmats = []\n",
    "\n",
    "S1_pdiags = []\n",
    "T2_pdiags = []\n",
    "\n",
    "S1_dmats_rel = []\n",
    "T2_dmats_rel = []\n",
    "\n",
    "S1_pdiags_rel = []\n",
    "T2_pdiags_rel = []\n",
    "\n",
    "S1_mflds = []\n",
    "T2_mflds = []\n",
    "\n",
    "S1_mflds_rel = []\n",
    "T2_mflds_rel = []\n",
    "\n",
    "for n, dim_out in enumerate(out_dims):\n",
    "    for m, dim_in in enumerate(in_dims):\n",
    "        for l in range(n_perms):\n",
    "            x = torch.Tensor(np.random.randn(dim_in, len(T2))).T\n",
    "            S1_emb = S1.T@x[:2]\n",
    "            T2_emb = T2.T@x\n",
    "            rand_model = FeedforwardNetwork(input_size=dim_in,hidden_sizes=[dim_out], init_type='none')\n",
    "            out_S1 = rand_model(S1_emb)[0]\n",
    "            out_T2 = rand_model(T2_emb)[0]\n",
    "\n",
    "            out_code_S1 = torch.sign(out_S1)\n",
    "            out_code_T2 = torch.sign(out_T2)\n",
    "            \n",
    "            region_ranks_S1[m,n,l] = rand_model.compute_rank(out_code_S1)\n",
    "            region_ranks_T2[m,n,l] = rand_model.compute_rank(out_code_T2)\n",
    "\n",
    "            id_points_S1 = code_equivalence_class(out_code_S1.detach().numpy(),region_ranks_S1[m,n,l],min_rank=2)\n",
    "            id_points_T2 = code_equivalence_class(out_code_T2.detach().numpy(),region_ranks_T2[m,n,l],min_rank=3)\n",
    "\n",
    "            codes_S1[m,n] = id_points_S1[1]\n",
    "            codes_T2[m,n] = id_points_T2[1]\n",
    "\n",
    "            if len(id_points_S1[0])==0:\n",
    "                S1_rel = Phom.relative_homology(S1.T,[[0]],metric,False,[1,250])\n",
    "            elif len(id_points_S1)==res:\n",
    "                S1_rel = Phom.relative_homology(S1.T,[np.arrange(0,res-1)],metric,False,[1,None])\n",
    "            else:\n",
    "                S1_rel = Phom.relative_homology(S1.T,id_points_S1[0],metric,False,[1,None])\n",
    "            S1_hom = Phom.homology_analysis(out_S1.detach(),metric,False,[1,250])\n",
    "                \n",
    "            S1_dmats.append(S1_hom[0])\n",
    "            S1_pdiags.append(S1_hom[1])\n",
    "            S1_dmats_rel.append(S1_rel[0])\n",
    "            S1_pdiags_rel.append(S1_rel[1])\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                S1_mflds.append(reducer.fit_transform(S1_dmats[-1]))\n",
    "                S1_mflds_rel.append(reducer.fit_transform(S1_dmats_rel[-1]))\n",
    "\n",
    "            if len(id_points_T2[0])==0:\n",
    "                T2_rel = Phom.relative_homology(T2.T,[[0]],metric,False,[2,250])\n",
    "            elif len(id_points_T2)==res:\n",
    "                T2_rel = Phom.relative_homology(T2.T,[np.arrange(0,res-1)],metric,False,[2,None])\n",
    "            else:\n",
    "                T2_rel = Phom.relative_homology(T2.T,id_points_T2[0],metric,False,[2,None])\n",
    "            T2_hom = Phom.homology_analysis(out_T2.detach(),metric,False,[2,250])\n",
    "            \n",
    "            T2_dmats.append(T2_hom[0])\n",
    "            T2_pdiags.append(T2_hom[1])\n",
    "            T2_dmats_rel.append(T2_rel[0])\n",
    "            T2_pdiags_rel.append(T2_rel[1])\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                T2_mflds.append(reducer.fit_transform(T2_dmats[-1]))\n",
    "                T2_mflds_rel.append(reducer.fit_transform(T2_dmats_rel[-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffd6b3-3462-40d6-8888-8535672e9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "custom_colormap = LinearSegmentedColormap.from_list('rank_decomp',['#c0bbffff','#bbfaffff','#ffbbbbff','#fff4bbff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d61a6-ac0a-4751-bbf0-d6f588d268f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 6\n",
    "fig,ax = plt.subplots(1,3,subplot_kw=dict(projection='3d'),figsize=(6,6),dpi=500)\n",
    "ax[0].scatter(S1[0],\n",
    "            S1[1],\n",
    "            S1[1],\n",
    "            s=50,vmin=0,vmax=3,\n",
    "            c=region_ranks_S1[id%4,int(np.floor(id/4))],cmap=custom_colormap)\n",
    "ax[0].scatter(S1[0],\n",
    "            S1[1],\n",
    "            S1[1],\n",
    "            s=2,c=codes_S1[id%4,int(np.floor(id/4))],cmap='winter')\n",
    "ax[0].axis('off')\n",
    "ax[1].view_init(elev=100, azim=290)\n",
    "ax[1].scatter(S1_mflds[id][:,0],\n",
    "            S1_mflds[id][:,1],\n",
    "            S1_mflds[id][:,2],\n",
    "            s=5,vmin=0,vmax=3,\n",
    "            c=region_ranks_S1[id%4,int(np.floor(id/4))],cmap=custom_colormap)\n",
    "ax[1].scatter(S1_mflds[id][:,0],\n",
    "            S1_mflds[id][:,1],\n",
    "            S1_mflds[id][:,2],\n",
    "            s=0.5,c=codes_S1[id%4,int(np.floor(id/4))],cmap='winter')\n",
    "ax[1].axis('off')\n",
    "ax[2].scatter(S1_mflds_rel[id][:,0],\n",
    "            S1_mflds_rel[id][:,1],\n",
    "            S1_mflds_rel[id][:,2],\n",
    "            s=5,c='#d33fa0ff')\n",
    "ax[2].axis('off')\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"/Users/kosio/Figures/MfldClassification/S1_examples.png\",dpi=500, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b00d8-beb2-482d-aede-a66dbfebf958",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 9\n",
    "fig,ax = plt.subplots(1,3,subplot_kw=dict(projection='3d'),figsize=(6,6),dpi=500)\n",
    "ax[0].view_init(elev=250, azim=100)\n",
    "ax[0].scatter(T2[0],\n",
    "            T2[1],\n",
    "            T2[2],\n",
    "            s=20,vmin=0,vmax=3,\n",
    "            c=region_ranks_T2[id%4,int(np.floor(id/4))],cmap=custom_colormap)\n",
    "#ax[0].scatter(T2[0],\n",
    "#            T2[1],\n",
    "#            T2[2],\n",
    "#            s=2,c=codes_T2[id%4,int(np.floor(id/4))],cmap='winter')\n",
    "ax[0].axis('off')\n",
    "ax[1].view_init(elev=280, azim=120)\n",
    "ax[1].scatter(T2_mflds[id][:,0],\n",
    "            T2_mflds[id][:,1],\n",
    "            T2_mflds[id][:,2],\n",
    "            s=20,vmin=0,vmax=3,\n",
    "            c=region_ranks_T2[id%4,int(np.floor(id/4))],cmap=custom_colormap)\n",
    "#ax[1].scatter(T2_mflds[id][:,0],\n",
    "#            T2_mflds[id][:,1],\n",
    "#            T2_mflds[id][:,2],\n",
    "#            s=2,c=codes_T2[id%4,int(np.floor(id/4))],cmap='winter')\n",
    "ax[1].axis('off')\n",
    "ax[2].view_init(elev=170, azim=165)\n",
    "ax[2].scatter(T2_mflds_rel[id][:,0],\n",
    "            T2_mflds_rel[id][:,1],\n",
    "            T2_mflds_rel[id][:,2],\n",
    "            s=4,c='#d33fa0ff')\n",
    "ax[2].axis('off')\n",
    "fig.tight_layout()\n",
    "#fig.savefig(\"/Users/kosio/Figures/MfldClassification/T2_examples.png\",dpi=500, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21261a1-74a8-496f-9527-d40381b82400",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_clrs = [clrs[0],clrs[2],clrs[4],clrs[6]]\n",
    "fig,ax = plt.subplots(2,len(out_dims)*len(in_dims),subplot_kw=dict(projection='3d'),figsize=(20,4))\n",
    "for i in range(len(out_dims)):\n",
    "    for j in range(len(in_dims)):\n",
    "        ax[0,i*len(out_dims)+j].scatter(S1_mflds[i*len(out_dims)+j][:,0],\n",
    "                                        S1_mflds[i*len(out_dims)+j][:,1],\n",
    "                                        S1_mflds[i*len(out_dims)+j][:,2],\n",
    "                                        s=0.4,c=region_ranks_S1[j,i,0],cmap='plasma',\n",
    "                                        vmin=0,vmax=2)\n",
    "        ax[0,i*len(out_dims)+j].axis('off')\n",
    "        ax[1,i*len(out_dims)+j].scatter(T2_mflds[i*len(out_dims)+j][:,0],\n",
    "                                        T2_mflds[i*len(out_dims)+j][:,1],\n",
    "                                        T2_mflds[i*len(out_dims)+j][:,2], \n",
    "                                        s=0.4, c=region_ranks_T2[j,i,0],cmap='plasma',\n",
    "                                        vmin=0,vmax=3)\n",
    "        ax[1,i*len(out_dims)+j].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda17e25-ff96-427a-a1da-e90758b7d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_clrs = [clrs[0],clrs[2],clrs[4],clrs[6]]\n",
    "fig,ax = plt.subplots(2,len(out_dims)*len(in_dims),subplot_kw=dict(projection='3d'),figsize=(20,4))\n",
    "for i in range(len(out_dims)):\n",
    "    for j in range(len(in_dims)):\n",
    "        ax[0,i*len(out_dims)+j].scatter(S1_mflds_rel[i*len(out_dims)+j][:,0],\n",
    "                                        S1_mflds_rel[i*len(out_dims)+j][:,1],\n",
    "                                        S1_mflds_rel[i*len(out_dims)+j][:,2],\n",
    "                                        s=0.4,color=sel_clrs[i])\n",
    "        ax[0,i*len(out_dims)+j].axis('off')\n",
    "        ax[1,i*len(out_dims)+j].scatter(T2_mflds_rel[i*len(out_dims)+j][:,0],\n",
    "                                        T2_mflds_rel[i*len(out_dims)+j][:,1],\n",
    "                                        T2_mflds_rel[i*len(out_dims)+j][:,2], \n",
    "                                        s=0.4, color=sel_clrs[i])\n",
    "        ax[1,i*len(out_dims)+j].axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3df29c-cbbd-4aec-ab18-c9639f81de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,len(out_dims)*len(in_dims),figsize=(20,4))\n",
    "for i in range(0,16):\n",
    "    ax[0,i].imshow(S1_dmats[i])\n",
    "    ax[0,i].axis('off')\n",
    "    plt.sca(ax[1,i])\n",
    "    plot_diagrams(S1_pdiags[i],legend=False)\n",
    "    ax[1,i].axis('off')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig2,ax2 = plt.subplots(2,len(out_dims)*len(in_dims),figsize=(20,4))\n",
    "for i in range(0,16):\n",
    "    ax2[0,i].imshow(T2_dmats[i])\n",
    "    ax2[0,i].axis('off')\n",
    "    plt.sca(ax2[1,i])\n",
    "    plot_diagrams(T2_pdiags[i],legend=False)\n",
    "    ax2[1,i].axis('off')\n",
    "fig2.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02347c46-183b-4188-8e74-eeab7ed50774",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,len(out_dims)*len(in_dims),figsize=(20,4))\n",
    "for i in range(0,16):\n",
    "    ax[0,i].imshow(S1_dmats_rel[i])\n",
    "    ax[0,i].axis('off')\n",
    "    plt.sca(ax[1,i])\n",
    "    plot_diagrams(S1_pdiags_rel[i],legend=False)\n",
    "    ax[1,i].axis('off')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig2,ax2 = plt.subplots(2,len(out_dims)*len(in_dims),figsize=(20,4))\n",
    "for i in range(0,16):\n",
    "    ax2[0,i].imshow(T2_dmats_rel[i])\n",
    "    ax2[0,i].axis('off')\n",
    "    plt.sca(ax2[1,i])\n",
    "    plot_diagrams(T2_pdiags_rel[i],legend=False)\n",
    "    ax2[1,i].axis('off')\n",
    "fig2.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da3d3e-83ba-4fcf-bed0-2a4e3e578f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for normal initialization\n",
    "import math\n",
    "\n",
    "mean = 0\n",
    "std = 0.1\n",
    "n_perms = 100\n",
    "out_dims = [2,5,10,25,50,100]#,500,1000]\n",
    "in_dims = [2,5,10,25,50,100]\n",
    "\n",
    "#eval points\n",
    "res = 100\n",
    "lims = 5\n",
    "\n",
    "region_ranks = np.zeros([len(in_dims),len(out_dims),n_perms])\n",
    "rank_est = np.zeros([len(in_dims),len(out_dims),n_perms])\n",
    "for m, dim_in in enumerate(in_dims):\n",
    "    for n, dim_out in enumerate(out_dims):\n",
    "        for l in range(n_perms):\n",
    "            x = torch.Tensor(lims*2*(np.random.rand(dim_in, res)-0.5)).T\n",
    "            rand_model = FeedforwardNetwork(input_size=dim_in,hidden_sizes=[dim_out],mean=mean,std=1/np.sqrt(dim_out), init_type='none')\n",
    "            out = rand_model(x)[0]\n",
    "            out_code = torch.sign(out).unique(dim=0)#[torch.sum(out[i]>0,axis=1) for i in range(len(out))]\n",
    "            region_ranks[m,n,l] = min(rand_model.compute_rank(out_code))\n",
    "#            region_ranks[m,n,l] = sum(out_code[0]<dim_in).item()>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561032a8-daaf-4d94-89bb-23bed7e9fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for scaling with index(R)\n",
    "n_neurons = 100\n",
    "inpt_dim = [25,50]\n",
    "R_indxs = np.arange(1,n_neurons,4)#[0,2,3,5,10,50,100,500]\n",
    "region_min_code = np.zeros([len(R_indxs),len(inpt_dim),n_perms])\n",
    "theory_curves = np.zeros([n_neurons,len(inpt_dim)])\n",
    "for r, r_indx in enumerate(R_indxs):\n",
    "    for n, in_dim in enumerate(inpt_dim):\n",
    "        for l in range(n_perms):\n",
    "            x = torch.Tensor(lims*2*(np.random.rand(in_dim, res)-0.5)).T\n",
    "            rand_model = FeedforwardNetwork(input_size=in_dim,hidden_sizes=[n_neurons])\n",
    "            R = torch.eye(n_neurons)\n",
    "            rand_inds = np.random.choice(np.arange(0,n_neurons),size=r_indx, replace=False)\n",
    "            R[rand_inds,rand_inds] = -1\n",
    "            rand_model.layers[0].weight = torch.nn.Parameter(rand_model.layers[0].weight)\n",
    "            #with torch.no_grad():\n",
    "                #rand_model.layers[0].weight[:49] = -rand_model.layers[0].weight[:49]\n",
    "            rand_model.layers[0].weight = torch.nn.Parameter(R@rand_model.layers[0].weight)\n",
    "            out = rand_model(x)[0]\n",
    "            out_code = torch.sign(out).unique(dim=0)#[torch.sum(out[i]>0,axis=1) for i in range(len(out))]\n",
    "            region_min_code[r,n,l] = min(rand_model.compute_rank(out_code))#torch.min(out_code[0]).item()\n",
    "        theory_curves[:,n] = np.concatenate([np.arange(0,int(n_neurons/2)), int(n_neurons/2)-np.arange(0,int(n_neurons/2))])\n",
    "        theory_curves[:,n] = np.minimum(theory_curves[:,n],in_dim*np.ones(n_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e580f-37ec-4029-8f01-0cc575ae7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for Dale-scaling with index(R)\n",
    "inpt_dim = 50\n",
    "R_indxs_dale = np.arange(1,inpt_dim,1)\n",
    "region_min_code_dale = np.zeros([len(R_indxs_dale),n_perms])\n",
    "region_max_code_dale = np.zeros([len(R_indxs_dale),n_perms])\n",
    "for r, r_indx in enumerate(R_indxs_dale):\n",
    "    for l in range(n_perms):\n",
    "        x = torch.Tensor(lims*2*(np.random.rand(inpt_dim, res))).T\n",
    "        rand_model = FeedforwardNetwork(input_size=inpt_dim,hidden_sizes=[n_neurons])\n",
    "        R = torch.eye(inpt_dim)\n",
    "        rand_inds = np.sort(np.random.choice(np.arange(0,inpt_dim),size=r_indx, replace=False))\n",
    "        R[rand_inds,rand_inds] = -4\n",
    "        rand_model.layers[0].weight = torch.nn.Parameter(rand_model.layers[0].weight)\n",
    "        rand_model.layers[0].weight = torch.nn.Parameter(rand_model.layers[0].weight@R)\n",
    "        out = rand_model(x)[0]\n",
    "        out_code = torch.sign(out).unique(dim=0)#[torch.sum(out[i]>0,axis=1) for i in range(len(out))]\n",
    "        code_rank = rand_model.compute_rank(out_code)\n",
    "        region_min_code_dale[r,l] = min(code_rank)#out_code[0]).item()\n",
    "        region_max_code_dale[r,l] = max(code_rank)\n",
    "#balanced_mode = np.logical_or(np.logical_and(np.mean(region_min_code_dale,1)!=0,np.mean(region_min_code_dale,1)!=n_neurons),\n",
    "#                              np.logical_and(np.mean(region_max_code_dale,1)!=0,np.mean(region_max_code_dale,1)!=n_neurons))\n",
    "region_min_code_dale[region_min_code_dale>inpt_dim] = inpt_dim\n",
    "region_max_code_dale[region_max_code_dale>inpt_dim] = inpt_dim\n",
    "balanced_mode = np.logical_and(np.mean(region_min_code_dale,1)<inpt_dim-1,(np.mean(region_max_code_dale,1)>inpt_dim-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34173d-f00c-4930-80b9-58d5d66ad59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#studying the number of low rank regions as a function of the mean of a distribution and the number of output neurons\n",
    "means = np.linspace(0,0.2,20)\n",
    "in_dim = 10\n",
    "\n",
    "region_ranks_mean = np.zeros([len(out_dims),len(means),n_perms])\n",
    "\n",
    "for d, dim in enumerate(out_dims):\n",
    "    for m, mean in enumerate(means):\n",
    "        for n in range(n_perms):\n",
    "            x = torch.Tensor(lims*2*(np.random.rand(in_dim, res)-0.5)).T\n",
    "            rand_model = FeedforwardNetwork(input_size=in_dim,hidden_sizes=[dim],mean=mean,std=std, init_type='normal')\n",
    "            out = rand_model(x)[0]\n",
    "            out_code = torch.sign(out).unique(dim=0)#[torch.sum(out[i]>0,axis=1) for i in range(len(out))]\n",
    "            region_ranks_mean[d,m,n] = min(rand_model.compute_rank(out_code))#sum(out_code[0]<in_dim).item()>0\n",
    "#min(*[sum(out_code[i]<in_dim).item()>0 for i in range(len(out))])#sum(out_code<in_dim).item()/res#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c9c7d-35f6-45f4-b359-0699e40daa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 10\n",
    "in_dim_ = 25\n",
    "region_ranks_depth = np.zeros([depth,len(out_dims),n_perms])\n",
    "\n",
    "for m, n_out in enumerate(out_dims):\n",
    "    print(m)\n",
    "    for n in range(n_perms):\n",
    "        ranks_at_points = np.zeros([depth,res])\n",
    "        x = torch.Tensor(lims*2*(np.random.rand(in_dim_, res)-0.5)).T\n",
    "        rand_model = FeedforwardNetwork(input_size=in_dim_,hidden_sizes=[n_out for k in range(depth)],mean=1,std=1,init_type='normal')\n",
    "        for i,x_i in enumerate(x):\n",
    "            ranks_at_points[:,i] = rand_model.compute_rank_at_point(x_i)\n",
    "        region_ranks_depth[:,m,n] = np.min(ranks_at_points,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19fb704-f192-4d8b-b753-462f7a096bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ranks_at_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4abf7-6f2c-4e00-91bf-1750e7ab61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(region_ranks_depth,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52203b35-3f78-4d46-bdc5-12cbb20bb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_height = 11.7/7\n",
    "fig_width = 8.3/1.3\n",
    "clrs = plt.cm.tab20.colors\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "fig, ax = plt.subplots(1,4,figsize=(fig_width,fig_height))#,dpi=300)\n",
    "\n",
    "for k in range(len(out_dims)):\n",
    "    ax[0].plot(out_dims, np.mean(region_ranks,2)[k],'-o',color=clrs[k],markersize=3)\n",
    "    ax[0].fill_between(out_dims, np.mean(region_ranks,2)[k]-np.std(region_ranks,2)[k],\n",
    "                       np.mean(region_ranks,2)[k]+np.std(region_ranks,2)[k], color=clrs[k],alpha=0.2)\n",
    "    ax[0].plot(out_dims, in_dims[k]*np.ones(len(out_dims)),'--',color=clrs[k],lw=0.5)\n",
    "    #ax[0].plot([in_dims[k],in_dims[k]], [0,out_dims[k]],'--',color=clrs[k],lw=0.5)\n",
    "    \n",
    "#ax[0].set_xlabel('$n_1$')\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_yscale('log')\n",
    "#ax[0].set_ylabel('$P[rank(\\Phi^1)<m]$')\n",
    "\n",
    "for k in range(len(out_dims)):\n",
    "    ax[1].plot(means,np.mean(region_ranks_mean[k],1),'-o',color=clrs[k],markersize=3)\n",
    "    ax[1].fill_between(means, np.mean(region_ranks_mean,2)[k]-np.std(region_ranks_mean,2)[k],\n",
    "                       np.mean(region_ranks_mean,2)[k]+np.std(region_ranks_mean,2)[k], color=clrs[k],alpha=0.2)\n",
    "ax[1].plot(means,in_dim*np.ones(len(means)),'k')\n",
    "#ax[1].set_yscale('log')\n",
    "\n",
    "\n",
    "ax[2].plot(theory_curves[:,0],'k',lw=4)\n",
    "ax[2].plot(theory_curves[:,1],'k',lw=4)\n",
    "ax[2].plot(R_indxs, np.mean(region_min_code[:,0],1),'-',color='cyan',lw=1.5,alpha=1)\n",
    "ax[2].plot(R_indxs, np.mean(region_min_code[:,1],1),'-',color='orange',lw=1.5,alpha=1)\n",
    "ax[2].fill_between(R_indxs,\n",
    "                   np.mean(region_min_code[:,0],1)-np.std(region_min_code[:,0],1),\n",
    "                   np.mean(region_min_code[:,0],1)+np.std(region_min_code[:,0],1),\n",
    "                   alpha=0.2,color='cyan')\n",
    "ax[2].fill_between(R_indxs,\n",
    "                   np.mean(region_min_code[:,1],1)-np.std(region_min_code[:,1],1),\n",
    "                   np.mean(region_min_code[:,1],1)+np.std(region_min_code[:,1],1),\n",
    "                   alpha=0.2,color='orange')\n",
    "ax[2].set_ylim(-1,51)\n",
    "#ax[1].set_xlabel('indx($R$)')\n",
    "#ax[0,1].set_xscale('log')\n",
    "#ax[1].set_ylabel('$min(C_{J})$')\n",
    "#ax[0,1].set_yscale('log')\n",
    "#ax[0,0].legend(in_dims)\n",
    "\n",
    "ax[3].plot(R_indxs_dale, np.mean(region_min_code_dale,1),'-',color='blue',lw=1.5,alpha=1)\n",
    "ax[3].plot(R_indxs_dale, np.mean(region_max_code_dale,1),'-',color='red',lw=1.5,alpha=1)\n",
    "ax[3].fill_between(R_indxs_dale,\n",
    "                   np.mean(region_min_code_dale,1)-np.std(region_min_code_dale,1),\n",
    "                   np.mean(region_min_code_dale,1)+np.std(region_min_code_dale,1),\n",
    "                   alpha=0.2,color='blue',zorder=-100)\n",
    "ax[3].fill_between(R_indxs_dale,\n",
    "                   np.mean(region_max_code_dale,1)-np.std(region_max_code_dale,1),\n",
    "                   np.mean(region_max_code_dale,1)+np.std(region_max_code_dale,1),\n",
    "                   alpha=0.2,color='red',zorder=-100)\n",
    "#ax[3].errorbar(R_indxs, np.mean(region_min_code_dale,1),yerr=1*np.std(region_min_code_dale,1),color='red', fmt='none',markersize=4)\n",
    "ax[3].fill_betweenx(np.arange(-10,60),R_indxs_dale[balanced_mode][0],R_indxs_dale[balanced_mode][-1],alpha=0.2,color='purple')\n",
    "ax[3].set_ylim(-1,51)\n",
    "\n",
    "#ax[2].set_xlabel('$\\mu$')\n",
    "#ax[2].set_ylabel('$P[rank(\\Phi^1)<m]$')\n",
    "\n",
    "#for k in range(len(R_indxs_2)):\n",
    "#    ax[3].plot(np.arange(1,depth+1), np.mean(region_ranks_depth[:,k],1),'-o',color=clrs[k],markersize=4)\n",
    "#ax[3].set_xlabel('depth')\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"/Users/kosio/Figures/MfldClassification/top_destr.png\",dpi=500, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49435fa4-43ac-484a-9f3f-ccd6558a03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_min_code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b401b48-9eab-4094-84e2-f198ef724b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
